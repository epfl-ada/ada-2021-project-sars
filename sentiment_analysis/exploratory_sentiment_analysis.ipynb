{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/antoinecrettenand/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/antoinecrettenand/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils_preprocessing import *\n",
    "\n",
    "DATA_PATH = \"../Data/\"\n",
    "MODEL = 'Vader'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for Sentiment Analysis\n",
    "We will run a baseline sentiment analysis with TextBlob implementation on our dataset i.e aggregated quotes based on mentions of 2012, 2016, 2020 U.S elections candidates. The goal of this preliminary analysis is :\n",
    "* Explore the distribution of positive/negative among quotes mentioning political candidates\n",
    "* Visualise partially the correctness of the baseline implementation through Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_obama_2012 = pd.read_csv(f\"{DATA_PATH}2012/obama_2012.zip\", compression=\"zip\")\n",
    "df_romney_2012 = pd.read_csv(f\"{DATA_PATH}2012/romney_2012.zip\", compression=\"zip\")\n",
    "df_trump_2016 = pd.read_csv(f\"{DATA_PATH}2016/trump_2016.zip\", compression=\"zip\")\n",
    "df_clinton_2016 = pd.read_csv(f\"{DATA_PATH}2016/clinton_2016.zip\", compression=\"zip\")\n",
    "df_trump_2020 = pd.read_csv(f\"{DATA_PATH}2020/trump_2020.zip\", compression=\"zip\")\n",
    "df_biden_2020 = pd.read_csv(f\"{DATA_PATH}2020/biden_2020.zip\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "Our baseline text preprocessing consists of :\n",
    "* Make text lowercase\n",
    "* Remove punctuation\n",
    "* Remove stopwords\n",
    "* Lemmatization\n",
    "\n",
    "Before applying sentiment analysis. See implementation in [utils_preprocessing.py](utils_preprocessing.py) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[process_sa] Prepared for sentiment analysis with tags: ['quotation_lemmatized', 'quotation_stemmed', 'quotation_tokenized', 'quotation_conc_lemmatized']\n",
      "[process_sa] Prepared for sentiment analysis with tags: ['quotation_lemmatized', 'quotation_stemmed', 'quotation_tokenized', 'quotation_conc_lemmatized']\n",
      "[process_sa] Prepared for sentiment analysis with tags: ['quotation_lemmatized', 'quotation_stemmed', 'quotation_tokenized', 'quotation_conc_lemmatized']\n",
      "[process_sa] Prepared for sentiment analysis with tags: ['quotation_lemmatized', 'quotation_stemmed', 'quotation_tokenized', 'quotation_conc_lemmatized']\n",
      "[process_sa] Prepared for sentiment analysis with tags: ['quotation_lemmatized', 'quotation_stemmed', 'quotation_tokenized', 'quotation_conc_lemmatized']\n",
      "[process_sa] Prepared for sentiment analysis with tags: ['quotation_lemmatized', 'quotation_stemmed', 'quotation_tokenized', 'quotation_conc_lemmatized']\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Unnamed: 0  Unnamed: 0.1            quoteID  \\\n0           3          1709  2016-07-07-033290   \n1           9          6715  2016-07-25-126140   \n2          11          7112  2016-08-09-004561   \n3          15         11168  2016-09-07-092168   \n4          16         13945  2016-09-07-003185   \n\n                                           quotation          speaker  \\\n0  I didn't want to delete it -- I would have nev...  Donald J. Trump   \n1  Wow, the Republican Convention went so smoothl...     Donald Trump   \n2  Although, the Second Amendment people -- maybe...     Donald Trump   \n3  She's totally unfit to be our commander in chief.  Donald J. Trump   \n4  A Trump supporter is fighting against just abo...        Brad Pitt   \n\n                      qids                 date  numOccurrences  \\\n0               ['Q22686']  2016-07-07 01:49:02               4   \n1  ['Q22686', 'Q27947481']  2016-07-25 00:00:00             171   \n2  ['Q22686', 'Q27947481']  2016-08-09 00:00:00            1183   \n3               ['Q22686']  2016-09-07 16:38:49               2   \n4    ['Q35332', 'Q373912']  2016-09-07 10:34:00              16   \n\n                                              probas  \\\n0  [['Donald J. Trump', '0.7791'], ['None', '0.21...   \n1  [['Donald Trump', '0.8662'], ['None', '0.1103'...   \n2  [['Donald Trump', '0.6569'], ['None', '0.2428'...   \n3  [['Donald J. Trump', '0.4223'], ['Donald Trump...   \n4  [['Brad Pitt', '0.3934'], ['None', '0.349'], [...   \n\n                                                urls phase month      type  \\\n0  ['http://mobile.nytimes.com/2016/07/07/us/poli...     E   Jul  NY Times   \n1  ['http://dailyherald.com/article/20160725/news...     E   Jul  NY Times   \n2  ['http://onenewspage.com/video/20160809/525505...     E   Aug  NY Times   \n3  ['http://www.nytimes.com/2016/09/08/us/politic...     E   Sep  NY Times   \n4  ['http://eonline.com/news/792842/brad-pitt-wei...     E   Sep  NY Times   \n\n      candidate                                quotation_tokenized  \\\n0  Donald Trump  [i, did not, want, to, delete, it, i, would, h...   \n1  Donald Trump  [wow, the, , convention, went, so, smoothly, c...   \n2  Donald Trump  [although, the, second, amendment, people, , t...   \n3  Donald Trump  [she is, totally, unfit, to, , our, commander,...   \n4  Donald Trump  [a, trump, supporter, , fighting, against, jus...   \n\n                                   quotation_stemmed  \\\n0  [did not, want, delet, would, never, delet, pe...   \n1  [wow, , convent, went, smoothli, compar, dem, ...   \n2  [although, second, amend, peopl, , , do not, k...   \n3            [she i, total, unfit, , command, chief]   \n4               [trump, support, , fight, , everyth]   \n\n                                quotation_lemmatized  \\\n0  [did not, want, delete, would, never, deleted,...   \n1  [wow, , convention, went, smoothly, compared, ...   \n2  [although, second, amendment, people, , , do n...   \n3       [she is, totally, unfit, , commander, chief]   \n4       [trump, supporter, , fighting, , everything]   \n\n                           quotation_conc_lemmatized  \n0  did not want delete would never deleted people...  \n1  wow  convention went smoothly compared dems to...  \n2     although second amendment people   do not know  \n3              she is totally unfit  commander chief  \n4              trump supporter  fighting  everything  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>quoteID</th>\n      <th>quotation</th>\n      <th>speaker</th>\n      <th>qids</th>\n      <th>date</th>\n      <th>numOccurrences</th>\n      <th>probas</th>\n      <th>urls</th>\n      <th>phase</th>\n      <th>month</th>\n      <th>type</th>\n      <th>candidate</th>\n      <th>quotation_tokenized</th>\n      <th>quotation_stemmed</th>\n      <th>quotation_lemmatized</th>\n      <th>quotation_conc_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>1709</td>\n      <td>2016-07-07-033290</td>\n      <td>I didn't want to delete it -- I would have nev...</td>\n      <td>Donald J. Trump</td>\n      <td>['Q22686']</td>\n      <td>2016-07-07 01:49:02</td>\n      <td>4</td>\n      <td>[['Donald J. Trump', '0.7791'], ['None', '0.21...</td>\n      <td>['http://mobile.nytimes.com/2016/07/07/us/poli...</td>\n      <td>E</td>\n      <td>Jul</td>\n      <td>NY Times</td>\n      <td>Donald Trump</td>\n      <td>[i, did not, want, to, delete, it, i, would, h...</td>\n      <td>[did not, want, delet, would, never, delet, pe...</td>\n      <td>[did not, want, delete, would, never, deleted,...</td>\n      <td>did not want delete would never deleted people...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>6715</td>\n      <td>2016-07-25-126140</td>\n      <td>Wow, the Republican Convention went so smoothl...</td>\n      <td>Donald Trump</td>\n      <td>['Q22686', 'Q27947481']</td>\n      <td>2016-07-25 00:00:00</td>\n      <td>171</td>\n      <td>[['Donald Trump', '0.8662'], ['None', '0.1103'...</td>\n      <td>['http://dailyherald.com/article/20160725/news...</td>\n      <td>E</td>\n      <td>Jul</td>\n      <td>NY Times</td>\n      <td>Donald Trump</td>\n      <td>[wow, the, , convention, went, so, smoothly, c...</td>\n      <td>[wow, , convent, went, smoothli, compar, dem, ...</td>\n      <td>[wow, , convention, went, smoothly, compared, ...</td>\n      <td>wow  convention went smoothly compared dems to...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11</td>\n      <td>7112</td>\n      <td>2016-08-09-004561</td>\n      <td>Although, the Second Amendment people -- maybe...</td>\n      <td>Donald Trump</td>\n      <td>['Q22686', 'Q27947481']</td>\n      <td>2016-08-09 00:00:00</td>\n      <td>1183</td>\n      <td>[['Donald Trump', '0.6569'], ['None', '0.2428'...</td>\n      <td>['http://onenewspage.com/video/20160809/525505...</td>\n      <td>E</td>\n      <td>Aug</td>\n      <td>NY Times</td>\n      <td>Donald Trump</td>\n      <td>[although, the, second, amendment, people, , t...</td>\n      <td>[although, second, amend, peopl, , , do not, k...</td>\n      <td>[although, second, amendment, people, , , do n...</td>\n      <td>although second amendment people   do not know</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>11168</td>\n      <td>2016-09-07-092168</td>\n      <td>She's totally unfit to be our commander in chief.</td>\n      <td>Donald J. Trump</td>\n      <td>['Q22686']</td>\n      <td>2016-09-07 16:38:49</td>\n      <td>2</td>\n      <td>[['Donald J. Trump', '0.4223'], ['Donald Trump...</td>\n      <td>['http://www.nytimes.com/2016/09/08/us/politic...</td>\n      <td>E</td>\n      <td>Sep</td>\n      <td>NY Times</td>\n      <td>Donald Trump</td>\n      <td>[she is, totally, unfit, to, , our, commander,...</td>\n      <td>[she i, total, unfit, , command, chief]</td>\n      <td>[she is, totally, unfit, , commander, chief]</td>\n      <td>she is totally unfit  commander chief</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>13945</td>\n      <td>2016-09-07-003185</td>\n      <td>A Trump supporter is fighting against just abo...</td>\n      <td>Brad Pitt</td>\n      <td>['Q35332', 'Q373912']</td>\n      <td>2016-09-07 10:34:00</td>\n      <td>16</td>\n      <td>[['Brad Pitt', '0.3934'], ['None', '0.349'], [...</td>\n      <td>['http://eonline.com/news/792842/brad-pitt-wei...</td>\n      <td>E</td>\n      <td>Sep</td>\n      <td>NY Times</td>\n      <td>Donald Trump</td>\n      <td>[a, trump, supporter, , fighting, against, jus...</td>\n      <td>[trump, support, , fight, , everyth]</td>\n      <td>[trump, supporter, , fighting, , everything]</td>\n      <td>trump supporter  fighting  everything</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess data for sentiment analysis\n",
    "tags = ['quotation_lemmatized', 'quotation_stemmed', 'quotation_tokenized', 'quotation_conc_lemmatized']\n",
    "df_trump_2016 = preprocess_data_for_sentiment_analysis(df_trump_2016, tags=tags)\n",
    "df_trump_2020 = preprocess_data_for_sentiment_analysis(df_trump_2020, tags=tags)\n",
    "df_clinton_2016 = preprocess_data_for_sentiment_analysis(df_clinton_2016, tags=tags)\n",
    "df_biden_2020 = preprocess_data_for_sentiment_analysis(df_biden_2020, tags=tags)\n",
    "df_obama_2012 = preprocess_data_for_sentiment_analysis(df_obama_2012, tags=tags)\n",
    "df_romney_2012 = preprocess_data_for_sentiment_analysis(df_romney_2012, tags=tags)\n",
    "\n",
    "df_trump_2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "Our baseline sentiment analysis consists of using TextBlob's sentiment analysis implementation which makes us of NLTK and pattern. The sentiment property is a namedtuple of the form Sentiment(polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective. We separate the tuple and append two columns with the retrieved values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset (13403, 20) with Vader in 1.0813910961151123 seconds.\n",
      "Processed dataset (16098, 20) with Vader in 1.1154811382293701 seconds.\n",
      "Processed dataset (10092, 20) with Vader in 0.8043718338012695 seconds.\n",
      "Processed dataset (4632, 20) with Vader in 0.41755223274230957 seconds.\n",
      "Processed dataset (6976, 20) with Vader in 0.7638850212097168 seconds.\n",
      "Processed dataset (2733, 20) with Vader in 0.3224828243255615 seconds.\n"
     ]
    }
   ],
   "source": [
    "df_obama_2012_sa = expand_quotations_with_polarity_subjectivity(df_obama_2012, column='quotation_conc_lemmatized', model=MODEL)\n",
    "df_romney_2012_sa = expand_quotations_with_polarity_subjectivity(df_romney_2012, column='quotation_conc_lemmatized', model=MODEL)\n",
    "\n",
    "df_trump_2016_sa = expand_quotations_with_polarity_subjectivity(df_trump_2016, column='quotation_conc_lemmatized', model=MODEL)\n",
    "df_clinton_2016_sa = expand_quotations_with_polarity_subjectivity(df_clinton_2016, column='quotation_conc_lemmatized', model=MODEL)\n",
    "\n",
    "df_trump_2020_sa = expand_quotations_with_polarity_subjectivity(df_trump_2020, column='quotation_conc_lemmatized', model=MODEL)\n",
    "df_biden_2020_sa = expand_quotations_with_polarity_subjectivity(df_biden_2020, column='quotation_conc_lemmatized', model=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save to CSV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "sentiment_analysis_datapath = f\"{DATA_PATH}preprocessed/\"\n",
    "\n",
    "df_obama_2012_sa.to_csv(f'{sentiment_analysis_datapath}2012_obama_quotes_{MODEL}_processed.csv')\n",
    "df_romney_2012_sa.to_csv(f'{sentiment_analysis_datapath}2012_romney_quotes_{MODEL}_processed.csv')\n",
    "\n",
    "df_trump_2016_sa.to_csv(f'{sentiment_analysis_datapath}2016_trump_quotes_{MODEL}_processed.csv')\n",
    "df_clinton_2016_sa.to_csv(f'{sentiment_analysis_datapath}2016_clinton_quotes_{MODEL}_processed.csv')\n",
    "\n",
    "df_trump_2020_sa.to_csv(f'{sentiment_analysis_datapath}2020_trump_quotes_{MODEL}_processed.csv')\n",
    "df_biden_2020_sa.to_csv(f'{sentiment_analysis_datapath}2020_biden_quotes_{MODEL}_processed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read from CSV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentiment_analysis_datapath = f\"{DATA_PATH}preprocessed/\"\n",
    "MODEL = 'TextBlob'\n",
    "\n",
    "df_obama_2012_sa = pd.read_csv(f'{sentiment_analysis_datapath}2012_obama_quotes_{MODEL}_processed.csv')\n",
    "df_romney_2012_sa = pd.read_csv(f'{sentiment_analysis_datapath}2012_romney_quotes_{MODEL}_processed.csv')\n",
    "\n",
    "df_trump_2016_sa = pd.read_csv(f'{sentiment_analysis_datapath}2016_trump_quotes_{MODEL}_processed.csv')\n",
    "df_clinton_2016_sa = pd.read_csv(f'{sentiment_analysis_datapath}2016_clinton_quotes_{MODEL}_processed.csv')\n",
    "\n",
    "df_trump_2020_sa = pd.read_csv(f'{sentiment_analysis_datapath}2020_trump_quotes_{MODEL}_processed.csv')\n",
    "df_biden_2020_sa = pd.read_csv(f'{sentiment_analysis_datapath}2020_biden_quotes_{MODEL}_processed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the frequency distributions of polarity and subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the frequency distribution of the polarity and subjectivity computed from the quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 2, figsize=(15, 20), sharey=True)\n",
    "\n",
    "sns.histplot(df_obama_2012_sa['quotation_polarity'], ax=axes[0][0])\n",
    "axes[0][0].set_title(f'Polarity distribution - 2012 - \\'Obama\\' - over {len(df_obama_2012_sa)} quotes')\n",
    "sns.histplot(df_obama_2012_sa['quotation_subjectivity'], ax=axes[0][1])\n",
    "axes[0][1].set_title(f'Subjectivity distribution - 2012 - \\'Obama\\' - over {len(df_obama_2012_sa)} quotes')\n",
    "\n",
    "sns.histplot(df_romney_2012_sa['quotation_polarity'], ax=axes[1][0])\n",
    "axes[1][0].set_title(f'Polarity distribution - 2012 - \\'Romney\\' - over {len(df_romney_2012_sa)} quotes')\n",
    "sns.histplot(df_romney_2012_sa['quotation_subjectivity'], ax=axes[1][1])\n",
    "axes[1][1].set_title(f'Subjectivity distribution - 2012 - \\'Romney\\' - over {len(df_romney_2012_sa)} quotes')\n",
    "\n",
    "sns.histplot(df_trump_2016_sa['quotation_polarity'], ax=axes[2][0])\n",
    "axes[2][0].set_title(f'Polarity distribution - 2016 - \\'Trump\\' - over {len(df_trump_2016_sa)} quotes')\n",
    "sns.histplot(df_trump_2016_sa['quotation_subjectivity'], ax=axes[2][1])\n",
    "axes[2][1].set_title(f'Subjectivity distribution - 2016 - \\'Trump\\' - over {len(df_trump_2016_sa)} quotes')\n",
    "\n",
    "sns.histplot(df_clinton_2016_sa['quotation_polarity'], ax=axes[3][0])\n",
    "axes[3][0].set_title(f'Polarity distribution - 2016 - \\'Clinton\\' - over {len(df_clinton_2016_sa)} quotes')\n",
    "sns.histplot(df_clinton_2016_sa['quotation_subjectivity'], ax=axes[3][1])\n",
    "axes[3][1].set_title(f'Subjectivity distribution - 2016 - \\'Clinton\\' - over {len(df_clinton_2016_sa)} quotes')\n",
    "\n",
    "sns.histplot(df_trump_2020_sa['quotation_polarity'], ax=axes[4][0])\n",
    "axes[4][0].set_title(f'Polarity distribution - 2020 - \\'Trump\\' - over {len(df_trump_2020_sa)} quotes')\n",
    "sns.histplot(df_trump_2020_sa['quotation_subjectivity'], ax=axes[4][1])\n",
    "axes[4][1].set_title(f'Subjectivity distribution - 2020 - \\'Trump\\' - over {len(df_trump_2020_sa)} quotes')\n",
    "\n",
    "sns.histplot(df_biden_2020_sa['quotation_polarity'], ax=axes[5][0])\n",
    "axes[5][0].set_title(f'Polarity distribution - 2020 - \\'Biden\\' - over {len(df_biden_2020_sa)} quotes')\n",
    "sns.histplot(df_biden_2020_sa['quotation_subjectivity'], ax=axes[5][1])\n",
    "axes[5][1].set_title(f'Subjectivity distribution - 2020 - \\'Biden\\' - over {len(df_biden_2020_sa)} quotes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the majority of quotes are analyzed as neutral. This could be a bias of the dataset as well as our sentiment analysis bias. We figured that the choice of stopwords to be removed from the strings is crucial to attributing positive or negative values. When comparing different models, we should pay attention to that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline of polarity and subjectivity distribution over 2016 and 2020 elections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the polarity and subjectivity distributions over time aggregated by month and candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_for_visualisation(df_candidates, months, candidates, subjectivity=False):\n",
    "\n",
    "    metric = 'polarity'\n",
    "    if subjectivity:\n",
    "        metric = 'subjectivity'\n",
    "\n",
    "    # aggregate data over month and candidate\n",
    "    tmp = df_candidates[['month', f'quotation_{metric}']].groupby([df_candidates.month, df_candidates.candidate]).mean()[f'quotation_{metric}']\n",
    "    cross = []\n",
    "    for candidate in candidates:\n",
    "        for month in months:\n",
    "            cross.append([candidate, month])\n",
    "\n",
    "    # magic trick to convert to standard df\n",
    "    tmp = pd.DataFrame([[month, tmp.at[month][candidate], candidate] for candidate, month in cross], columns=['month', f'quotation_{metric}', 'candidate'])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_2012 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov']\n",
    "months_2016 = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov']\n",
    "months_2020 = ['Jan', 'Feb', 'Mar', 'Apr']\n",
    "candidates_2012 = ['Mitt Romney', 'Barack Obama']\n",
    "candidates_2016 = ['Donald Trump', 'Hillary Clinton']\n",
    "candidates_2020 = ['Donald Trump', 'Joe Biden']\n",
    "\n",
    "df_candidates_2012 = pd.concat([df_obama_2012_sa, df_romney_2012_sa], ignore_index=True)\n",
    "df_candidates_2016 = pd.concat([df_trump_2016_sa, df_clinton_2016_sa], ignore_index=True)\n",
    "df_candidates_2020 = pd.concat([df_trump_2020_sa, df_biden_2020_sa], ignore_index=True)\n",
    "\n",
    "# The quotes are aggregated and averaged by month and by candidate\n",
    "df_candidates_2012_polarity_processed = preprocess_data_for_visualisation(df_candidates_2012, months_2012, candidates_2012)\n",
    "df_candidates_2012_subjectivity_processed = preprocess_data_for_visualisation(df_candidates_2012, months_2012, candidates_2012, subjectivity=True)\n",
    "df_candidates_2016_polarity_processed = preprocess_data_for_visualisation(df_candidates_2016, months_2016, candidates_2016)\n",
    "df_candidates_2016_subjectivity_processed = preprocess_data_for_visualisation(df_candidates_2016, months_2016, candidates_2016, subjectivity=True)\n",
    "df_candidates_2020_polarity_processed = preprocess_data_for_visualisation(df_candidates_2020, months_2020, candidates_2020)\n",
    "df_candidates_2020_subjectivity_processed = preprocess_data_for_visualisation(df_candidates_2020, months_2020, candidates_2020, subjectivity=True)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(20,20))\n",
    "fig.tight_layout(h_pad=5)\n",
    "\n",
    "axs[0][0].set_title(\"Polarity distribution of Candidate Name Mentions Quotes for 2012 US Elections\")\n",
    "sns.barplot(x='month', y='quotation_polarity', data=df_candidates_2012_polarity_processed, hue=\"candidate\", order=months_2012, ax=axs[0][0], palette=[\"#fe1100\",'#6699d8'])\n",
    "axs[0][0].legend(loc='upper right')\n",
    "axs[1][0].set_title(\"Polarity distribution of Candidate Name Mentions Quotes for 2016 US Elections\")\n",
    "sns.barplot(x='month', y='quotation_polarity', data=df_candidates_2016_polarity_processed, hue=\"candidate\", order=months_2016, ax=axs[1][0], palette=[\"#fe1100\",'#6699d8'])\n",
    "axs[1][0].legend(loc='upper right')\n",
    "axs[2][0].set_title(\"Polarity distribution Candidate Name Mentions for 2020 US Elections\")\n",
    "sns.barplot(x='month', y='quotation_polarity', data=df_candidates_2020_polarity_processed, hue=\"candidate\", order=months_2020, ax=axs[2][0], palette=[\"#fe1100\",'#6699d8'])\n",
    "axs[2][0].legend(loc='upper right')\n",
    "\n",
    "axs[0][1].set_title(\"Subjectivity distribution of Candidate Name Mentions for 2012 US Elections\")\n",
    "sns.barplot(x='month', y='quotation_subjectivity', data=df_candidates_2012_subjectivity_processed, hue=\"candidate\", order=months_2012, ax=axs[0][1], palette=[\"#fe1100\",'#6699d8'])\n",
    "axs[0][1].legend(loc='upper right')\n",
    "axs[1][1].set_title(\"Subjectivity distribution of Candidate Name Mentions for 2016 US Elections\")\n",
    "sns.barplot(x='month', y='quotation_subjectivity', data=df_candidates_2016_subjectivity_processed, hue=\"candidate\", order=months_2016, ax=axs[1][1], palette=[\"#fe1100\",'#6699d8'])\n",
    "axs[1][1].legend(loc='upper right')\n",
    "axs[2][1].set_title(\"Subjectivity distribution of Candidate Name Mentions for 2020 US Elections\")\n",
    "sns.barplot(x='month', y='quotation_subjectivity', data=df_candidates_2020_subjectivity_processed, hue=\"candidate\", order=months_2020, ax=axs[2][1], palette=[\"#fe1100\",'#6699d8'])\n",
    "axs[2][1].legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the change in polarity (y-axis) from a month to another is very small in most cases which makes it difficult conclude a meaningful statistical change. However we observe a very different timeline for 2016 election.\n",
    "\n",
    "Finally, the quotes from 2020 don't extend past April. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordcloud of positive and negative quotes (80% threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to visualise assess the correctness of our sentiment analysis is to plot the word cloud related to the most positive or negatives quotes (>80%). We can visually see if the most present words have indeed a positive/negative connotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud          \n",
    "import matplotlib.pyplot as plt   \n",
    "\n",
    "def plot_word_cloud(type_,string: str, filter_keywords=[]):\n",
    "    for keyword in filter_keywords:\n",
    "        string = string.replace(keyword, '')\n",
    "\n",
    "    string_split = Counter(string.split(' '))\n",
    "    counts = {k:v for k, v in string_split.most_common(200)}\n",
    "\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    plt.title('word cloud '+type_ ,fontsize=30, pad=25)\n",
    "    wordcloud = WordCloud(background_color=\"white\", contour_width=3, contour_color='steelblue').generate_from_frequencies(counts)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_positive_sentiment(df_quotes, threshold=0.5):\n",
    "    #map [0, 1] to [-1, 1]\n",
    "    polarity_thresh = threshold * 2 - 1\n",
    "    polarity_quotes = df_quotes[df_quotes['quotation_polarity'] > polarity_thresh]\n",
    "    subjective_quotes = df_quotes[df_quotes['quotation_subjectivity'] > threshold]\n",
    "    return polarity_quotes, subjective_quotes\n",
    "\n",
    "def extract_negative_sentiment(df_quotes, threshold=0.5):\n",
    "    #map [0, 1] to [-1, 1]\n",
    "    polarity_thresh = threshold * 2 - 1\n",
    "    polarity_quotes = df_quotes[df_quotes['quotation_polarity'] < -polarity_thresh]\n",
    "    subjective_quotes = df_quotes[df_quotes['quotation_subjectivity'] < threshold]\n",
    "    return polarity_quotes, subjective_quotes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter quotes with only positive polarity (>0.8) which corresponds to a higher confidence in prediction.\n",
    "positive_pol_quotes, _ = extract_positive_sentiment(df_candidates_2012, threshold=0.8)\n",
    "negative_pol_quotes, _ = extract_negative_sentiment(df_candidates_2012, threshold=0.8)\n",
    "\n",
    "positive_long_string = ' '.join(list(' '.join(x) for x in positive_pol_quotes['quotation_lemmatized'].values))\n",
    "negative_long_string = ' '.join(list(' '.join(x) for x in negative_pol_quotes['quotation_lemmatized'].values))\n",
    "\n",
    "plot_word_cloud('positive',positive_long_string, filter_keywords=['mitt', 'romney', 'barack', 'obama'])\n",
    "plot_word_cloud('negative',negative_long_string, filter_keywords=['mitt', 'romney', 'barack', 'obama'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Our initial baseline sentiment analysis implementation seems to be working properly i.e the most positive/negative quoted words have positive/negative meaning. Furthermore, We need a golden standard to compute the true accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}